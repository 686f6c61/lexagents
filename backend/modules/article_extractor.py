# -*- coding: utf-8 -*-
"""
LexAgents - Sistema Multi-Agente de Extracci√≥n Legal
https://github.com/686f6c61/lexagents

M√≥dulo 4: Extractor de Art√≠culos
Extrae art√≠culos espec√≠ficos de leyes del BOE.
Parsea el HTML consolidado y extrae art√≠culos con su contenido completo.

Author: 686f6c61
Version: 0.2.0
License: MIT
"""

import re
import logging
from typing import Dict, List, Optional, Tuple
from bs4 import BeautifulSoup
from dataclasses import dataclass, asdict

logger = logging.getLogger(__name__)


@dataclass
class Articulo:
    """Representa un art√≠culo de una ley"""
    numero: str  # "23", "23.2", "23.2.b"
    titulo: Optional[str]  # T√≠tulo del art√≠culo (si existe)
    contenido: str  # Texto completo del art√≠culo
    apartados: List[str]  # Lista de apartados (si tiene)
    html_original: str  # HTML original del art√≠culo
    ley_referencia: str  # Ley a la que pertenece (ej: "Ley 39/2015")


class ArticleExtractor:
    """Extractor de art√≠culos de legislaci√≥n del BOE"""

    def __init__(self):
        self.soup = None
        self.articulos = []

        # Patrones para identificar art√≠culos
        self.patrones_articulo = [
            r'Art√≠culo\s+(\d+(?:\.\d+)?(?:\.[a-z])?)',
            r'Art\.\s+(\d+(?:\.\d+)?(?:\.[a-z])?)',
            r'Art\s+(\d+(?:\.\d+)?(?:\.[a-z])?)',
        ]

    def extraer_de_html(self, html_content: str, ley_referencia: str = "") -> List[Dict]:
        """
        Extrae todos los art√≠culos de un HTML del BOE

        Args:
            html_content: HTML de la ley consolidada
            ley_referencia: Referencia de la ley (ej: "Ley 39/2015")

        Returns:
            Lista de art√≠culos como diccionarios
        """
        logger.info(f"üìÑ Extrayendo art√≠culos de: {ley_referencia or 'ley sin especificar'}")

        self.soup = BeautifulSoup(html_content, 'html.parser')
        self.articulos = []

        # Buscar todos los art√≠culos en el HTML
        articulos_encontrados = self._buscar_articulos()

        # Parsear cada art√≠culo
        for num, html_elem in articulos_encontrados:
            try:
                articulo = self._parsear_articulo(num, html_elem, ley_referencia)
                if articulo:
                    self.articulos.append(articulo)
            except Exception as e:
                logger.warning(f"Error parseando art√≠culo {num}: {e}")

        logger.info(f"‚úÖ Extra√≠dos {len(self.articulos)} art√≠culos")

        # Convertir a diccionarios para serializaci√≥n
        return [asdict(art) for art in self.articulos]

    def extraer_articulo_especifico(
        self,
        html_content: str,
        numero_articulo: str,
        ley_referencia: str = ""
    ) -> Optional[Dict]:
        """
        Extrae un art√≠culo espec√≠fico por su n√∫mero

        Args:
            html_content: HTML de la ley consolidada
            numero_articulo: N√∫mero del art√≠culo (ej: "23", "23.2", "23.2.b")
            ley_referencia: Referencia de la ley

        Returns:
            Dict con el art√≠culo o None si no se encuentra
        """
        logger.info(f"üîç Buscando art√≠culo {numero_articulo} en {ley_referencia}")

        # Extraer todos primero
        todos_articulos = self.extraer_de_html(html_content, ley_referencia)

        # Buscar el art√≠culo espec√≠fico
        for art in todos_articulos:
            if art['numero'] == numero_articulo:
                logger.info(f"‚úÖ Art√≠culo {numero_articulo} encontrado")
                return art

            # Tambi√©n buscar por coincidencia parcial (art. 23 incluye 23.1, 23.2, etc.)
            if art['numero'].startswith(f"{numero_articulo}."):
                logger.info(f"‚úÖ Encontrado apartado: {art['numero']}")
                return art

        logger.warning(f"‚ùå Art√≠culo {numero_articulo} no encontrado")
        return None

    def _buscar_articulos(self) -> List[Tuple[str, any]]:
        """
        Busca todos los elementos que representan art√≠culos en el HTML

        Returns:
            Lista de tuplas (numero_articulo, elemento_html)
        """
        articulos = []

        # Estrategia 1: Buscar por estructura del BOE
        # El BOE suele usar <div class="articulo"> o <p class="articulo">
        for elem in self.soup.find_all(['div', 'p', 'h3', 'h4'], class_=re.compile(r'articulo|art\b', re.I)):
            numero = self._extraer_numero_articulo(elem.get_text())
            if numero:
                articulos.append((numero, elem))

        # Estrategia 2: Buscar por texto que contenga "Art√≠culo X"
        if not articulos:
            for elem in self.soup.find_all(['p', 'div', 'h3', 'h4']):
                texto = elem.get_text(strip=True)
                numero = self._extraer_numero_articulo(texto)
                if numero:
                    articulos.append((numero, elem))

        # Eliminar duplicados
        articulos_unicos = {}
        for num, elem in articulos:
            if num not in articulos_unicos:
                articulos_unicos[num] = elem

        logger.debug(f"Encontrados {len(articulos_unicos)} art√≠culos √∫nicos")
        return list(articulos_unicos.items())

    def _extraer_numero_articulo(self, texto: str) -> Optional[str]:
        """
        Extrae el n√∫mero de art√≠culo de un texto

        Args:
            texto: Texto que puede contener "Art√≠culo 123"

        Returns:
            N√∫mero del art√≠culo (ej: "123", "123.2") o None
        """
        for patron in self.patrones_articulo:
            match = re.search(patron, texto, re.IGNORECASE)
            if match:
                return match.group(1)
        return None

    def _parsear_articulo(
        self,
        numero: str,
        elemento: any,
        ley_referencia: str
    ) -> Optional[Articulo]:
        """
        Parsea un elemento HTML como art√≠culo

        Args:
            numero: N√∫mero del art√≠culo
            elemento: Elemento BeautifulSoup
            ley_referencia: Referencia de la ley

        Returns:
            Objeto Articulo o None
        """
        # Extraer t√≠tulo (si existe)
        titulo = self._extraer_titulo_articulo(elemento)

        # Extraer contenido completo
        contenido = self._extraer_contenido_articulo(elemento)

        # Extraer apartados (numeraci√≥n interna)
        apartados = self._extraer_apartados(elemento)

        # HTML original
        html_original = str(elemento)

        if not contenido.strip():
            logger.warning(f"Art√≠culo {numero} sin contenido")
            return None

        return Articulo(
            numero=numero,
            titulo=titulo,
            contenido=contenido,
            apartados=apartados,
            html_original=html_original,
            ley_referencia=ley_referencia
        )

    def _extraer_titulo_articulo(self, elemento: any) -> Optional[str]:
        """
        Extrae el t√≠tulo del art√≠culo (si existe)

        Ejemplo: "Art√≠culo 23. Derecho a ser informado."
                 Devuelve: "Derecho a ser informado"
        """
        texto = elemento.get_text(strip=True)

        # Buscar patr√≥n: Art√≠culo X. T√≠tulo
        match = re.search(
            r'(?:Art√≠culo|Art\.?)\s+\d+(?:\.\d+)?(?:\.[a-z])?\s*\.\s*(.+?)(?:\.|$)',
            texto,
            re.IGNORECASE
        )

        if match:
            return match.group(1).strip()

        return None

    def _extraer_contenido_articulo(self, elemento: any) -> str:
        """
        Extrae el contenido completo del art√≠culo

        Args:
            elemento: Elemento BeautifulSoup

        Returns:
            Texto del art√≠culo limpio
        """
        # Obtener todo el texto del elemento y sus hermanos siguientes
        # hasta el pr√≥ximo art√≠culo

        contenido_partes = []

        # Texto del elemento actual
        texto = elemento.get_text(strip=True)
        contenido_partes.append(texto)

        # Buscar elementos siguientes hasta el pr√≥ximo art√≠culo
        siguiente = elemento.find_next_sibling()
        while siguiente:
            # Si encontramos otro art√≠culo, detenerse
            siguiente_texto = siguiente.get_text(strip=True)
            if self._extraer_numero_articulo(siguiente_texto):
                break

            # Si es un elemento de contenido, agregarlo
            if siguiente.name in ['p', 'div', 'ul', 'ol', 'li']:
                contenido_partes.append(siguiente_texto)

            siguiente = siguiente.find_next_sibling()

        # Unir todo el contenido
        contenido_completo = '\n'.join(contenido_partes)

        # Limpiar exceso de espacios en blanco
        contenido_completo = re.sub(r'\s+', ' ', contenido_completo)

        return contenido_completo.strip()

    def _extraer_apartados(self, elemento: any) -> List[str]:
        """
        Extrae los apartados de un art√≠culo (numeraci√≥n interna)

        Ejemplo:
        1. Primer apartado
        2. Segundo apartado
        a) Subapartado a
        b) Subapartado b
        """
        apartados = []

        # Buscar listas numeradas o con letras
        for lista in elemento.find_all(['ol', 'ul']):
            for item in lista.find_all('li'):
                texto = item.get_text(strip=True)
                if texto:
                    apartados.append(texto)

        # Buscar apartados en el texto plano
        texto = elemento.get_text()

        # Patr√≥n: 1. texto, 2. texto, etc.
        matches = re.findall(r'^\s*(\d+)\.\s+(.+?)(?=\n\s*\d+\.|$)', texto, re.MULTILINE)
        for num, contenido in matches:
            apartados.append(f"{num}. {contenido.strip()}")

        # Patr√≥n: a) texto, b) texto, etc.
        matches = re.findall(r'^\s*([a-z])\)\s+(.+?)(?=\n\s*[a-z]\)|$)', texto, re.MULTILINE)
        for letra, contenido in matches:
            apartados.append(f"{letra}) {contenido.strip()}")

        return apartados

    def buscar_articulos_por_patron(
        self,
        html_content: str,
        patron: str,
        ley_referencia: str = ""
    ) -> List[Dict]:
        """
        Busca art√≠culos que contengan un patr√≥n espec√≠fico en su contenido

        Args:
            html_content: HTML de la ley
            patron: Expresi√≥n regular a buscar
            ley_referencia: Referencia de la ley

        Returns:
            Lista de art√≠culos que coinciden
        """
        logger.info(f"üîç Buscando art√≠culos con patr√≥n: {patron}")

        todos_articulos = self.extraer_de_html(html_content, ley_referencia)

        coincidencias = []
        for art in todos_articulos:
            if re.search(patron, art['contenido'], re.IGNORECASE):
                coincidencias.append(art)

        logger.info(f"‚úÖ Encontrados {len(coincidencias)} art√≠culos con el patr√≥n")
        return coincidencias

    def estadisticas(self) -> Dict:
        """
        Devuelve estad√≠sticas sobre los art√≠culos extra√≠dos

        Returns:
            Dict con estad√≠sticas
        """
        if not self.articulos:
            return {
                'total_articulos': 0,
                'articulos_con_titulo': 0,
                'articulos_con_apartados': 0,
                'promedio_longitud': 0
            }

        return {
            'total_articulos': len(self.articulos),
            'articulos_con_titulo': sum(1 for a in self.articulos if a.titulo),
            'articulos_con_apartados': sum(1 for a in self.articulos if a.apartados),
            'promedio_longitud': sum(len(a.contenido) for a in self.articulos) / len(self.articulos)
        }


def extraer_articulo(
    html_content: str,
    numero_articulo: str,
    ley_referencia: str = ""
) -> Optional[Dict]:
    """
    Funci√≥n helper para extraer un art√≠culo espec√≠fico

    Args:
        html_content: HTML de la ley consolidada
        numero_articulo: N√∫mero del art√≠culo a extraer
        ley_referencia: Referencia de la ley

    Returns:
        Dict con el art√≠culo o None
    """
    extractor = ArticleExtractor()
    return extractor.extraer_articulo_especifico(
        html_content,
        numero_articulo,
        ley_referencia
    )


# Ejemplo de uso
if __name__ == "__main__":
    import sys
    from pathlib import Path

    # Configurar logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(message)s'
    )

    print("=" * 60)
    print("üìÑ TEST DE EXTRACCI√ìN DE ART√çCULOS")
    print("=" * 60)

    # Intentar cargar una ley desde el cach√©
    cache_dir = Path("../../data/cache/boe_leyes")
    cache_files = list(cache_dir.glob("*.json"))

    if not cache_files:
        print("‚ùå No hay leyes en cach√©. Ejecuta primero boe_downloader.py")
        sys.exit(1)

    # Cargar la primera ley del cach√©
    import json
    cache_file = cache_files[0]

    print(f"\nüìÇ Cargando: {cache_file.name}")

    with open(cache_file, 'r', encoding='utf-8') as f:
        ley_data = json.load(f)

    html_content = ley_data.get('contenido', '')
    ley_referencia = ley_data['metadata'].get('numero_oficial', 'Ley sin identificar')

    print(f"üìÑ Ley: {ley_data['metadata'].get('titulo', 'N/A')}")
    print("-" * 60)

    # Test 1: Extraer art√≠culo espec√≠fico (art√≠culo 23)
    extractor = ArticleExtractor()

    print("\nüîç Test 1: Extraer art√≠culo 23")
    articulo_23 = extractor.extraer_articulo_especifico(
        html_content,
        "23",
        ley_referencia
    )

    if articulo_23:
        print(f"‚úÖ Art√≠culo encontrado:")
        print(f"   N√∫mero: {articulo_23['numero']}")
        print(f"   T√≠tulo: {articulo_23['titulo'] or 'N/A'}")
        print(f"   Contenido (primeros 200 chars): {articulo_23['contenido'][:200]}...")
        print(f"   Apartados: {len(articulo_23['apartados'])}")
    else:
        print("‚ùå Art√≠culo 23 no encontrado")

    # Test 2: Extraer todos los art√≠culos
    print("\nüîç Test 2: Extraer todos los art√≠culos")
    todos = extractor.extraer_de_html(html_content, ley_referencia)
    print(f"‚úÖ Total de art√≠culos extra√≠dos: {len(todos)}")

    if todos:
        print(f"\nüìã Primeros 5 art√≠culos:")
        for art in todos[:5]:
            print(f"   - Art√≠culo {art['numero']}: {art['titulo'] or '(sin t√≠tulo)'}")

    # Test 3: Estad√≠sticas
    print(f"\nüìä Estad√≠sticas:")
    stats = extractor.estadisticas()
    for key, value in stats.items():
        print(f"   {key}: {value}")

    print("\n" + "=" * 60)
    print("‚úÖ TEST COMPLETADO")
    print("=" * 60)
